{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Class Model Demo: End-to-End Analysis\n",
    "\n",
    "This notebook demonstrates a complete workflow for latent class modeling of multivariate categorical data:\n",
    "\n",
    "1. **Data Generation**: Create synthetic data from a known latent class model\n",
    "2. **Model Selection**: Use BIC to automatically select the optimal number of classes\n",
    "3. **Model Fitting**: Estimate parameters using the EM algorithm\n",
    "4. **Results Analysis**: Evaluate model performance and parameter recovery\n",
    "\n",
    "**Note**: This notebook should be placed in the `demo/` folder of your project. All visualizations are displayed inline and no files are saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, we'll import the necessary libraries and configure our experiment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path to import from src\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our latent class modeling modules\n",
    "from src.dgp import LatentClassDGP\n",
    "from src.latent_class_modeling import LatentClassModel\n",
    "from src.model_selection import BICModelSelector\n",
    "from src.visualization import (\n",
    "    plot_bic_curve,\n",
    "    plot_mixture_weights,\n",
    "    plot_categorical_probabilities,\n",
    "    plot_class_assignments,\n",
    "    plot_posterior_uncertainty\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Configuration\n",
    "\n",
    "Here we define the key parameters for our synthetic data generation and model fitting:\n",
    "\n",
    "- **n**: Number of samples to generate\n",
    "- **K_true**: True number of latent classes in the data\n",
    "- **m**: Number of categorical variables (features)\n",
    "- **C**: Number of categories for each variable\n",
    "- **K_range**: Range of K values to test during BIC model selection\n",
    "\n",
    "These parameters are configurable - feel free to modify them to explore different scenarios!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURABLE PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Data generation parameters\n",
    "n = 2000           # Number of samples\n",
    "K_true = 3         # True number of latent classes\n",
    "m = 20             # Number of variables\n",
    "C = 3              # Number of categories per variable\n",
    "\n",
    "# Model selection parameters\n",
    "K_range = [1, 2, 3, 4, 5, 6]  # Range of K values to test\n",
    "\n",
    "# EM algorithm parameters\n",
    "max_iter = 500     # Maximum EM iterations\n",
    "tol = 1e-6         # Convergence tolerance\n",
    "n_init = 5         # Number of random initializations\n",
    "\n",
    "print(\"Experiment Configuration:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Sample size (n):              {n}\")\n",
    "print(f\"True number of classes (K):   {K_true}\")\n",
    "print(f\"Number of variables (m):      {m}\")\n",
    "print(f\"Categories per variable (C):  {C}\")\n",
    "print(f\"K range to test:              {K_range}\")\n",
    "print(f\"EM max iterations:            {max_iter}\")\n",
    "print(f\"Random initializations:       {n_init}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Data\n",
    "\n",
    "We'll generate synthetic data from a latent class model with known parameters. This allows us to evaluate how well our method can recover the true structure.\n",
    "\n",
    "The generative model is:\n",
    "\n",
    "$$P(X = x) = \\sum_{k=1}^K \\pi_k \\prod_{r=1}^m P(X^{(r)} = x^{(r)} | H = k)$$\n",
    "\n",
    "where:\n",
    "- $\\pi_k$ are the mixture weights (class probabilities)\n",
    "- $\\theta_{rkc} = P(X^{(r)} = c | H = k)$ are the categorical probabilities\n",
    "- $H$ is the latent class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generating process\n",
    "categories = [C] * m  # All variables have C categories\n",
    "dgp = LatentClassDGP(K=K_true, categories=categories, random_state=42)\n",
    "\n",
    "# Generate synthetic data\n",
    "X, H = dgp.generate_data(n)\n",
    "\n",
    "# Get true parameters\n",
    "true_params = dgp.get_true_parameters()\n",
    "true_pi = true_params['pi']\n",
    "true_theta = true_params['theta']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SYNTHETIC DATA GENERATED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Data shape: {X.shape} (samples √ó variables)\")\n",
    "print(f\"\\nTrue mixture weights (œÄ):\")\n",
    "for k in range(K_true):\n",
    "    print(f\"  Class {k}: œÄ_{k} = {true_pi[k]:.4f}\")\n",
    "print(f\"\\nTrue class distribution in generated data:\")\n",
    "for k in range(K_true):\n",
    "    count = np.sum(H == k)\n",
    "    proportion = count / n\n",
    "    print(f\"  Class {k}: {count} samples ({proportion:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Let's examine the generated data to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier viewing\n",
    "df = pd.DataFrame(X, columns=[f'Var_{r}' for r in range(m)])\n",
    "df['TrueClass'] = H\n",
    "\n",
    "print(\"\\nFirst 10 rows of generated data:\")\n",
    "print(df.head(10))\n",
    "\n",
    "print(\"\\nData summary statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of categories for a few variables\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, var_idx in enumerate([0, 1, 2, 3, 4, 5]):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Count categories by class\n",
    "    for k in range(K_true):\n",
    "        mask = H == k\n",
    "        values = X[mask, var_idx]\n",
    "        counts = np.bincount(values, minlength=C)\n",
    "        proportions = counts / counts.sum()\n",
    "        \n",
    "        ax.bar(np.arange(C) + k*0.25, proportions, width=0.25, \n",
    "               label=f'Class {k}', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Category', fontsize=10)\n",
    "    ax.set_ylabel('Proportion', fontsize=10)\n",
    "    ax.set_title(f'Variable {var_idx}', fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.set_xticks(np.arange(C) + 0.25)\n",
    "    ax.set_xticklabels(range(C))\n",
    "\n",
    "plt.suptitle('Category Distributions by True Latent Class', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThese plots show how different latent classes generate different\")\n",
    "print(\"category distributions for each variable. The separation between\")\n",
    "print(\"classes indicates how well they can be identified from the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Selection via BIC\n",
    "\n",
    "We'll use the Bayesian Information Criterion (BIC) to automatically select the optimal number of latent classes. BIC balances model fit with model complexity:\n",
    "\n",
    "$$\\text{BIC} = -2 \\cdot \\log L(\\Theta | X) + p \\cdot \\log(n)$$\n",
    "\n",
    "where:\n",
    "- $L(\\Theta | X)$ is the likelihood of the data given the parameters\n",
    "- $p$ is the number of free parameters\n",
    "- $n$ is the sample size\n",
    "\n",
    "Lower BIC values indicate better models. The penalty term ($p \\cdot \\log(n)$) prevents overfitting by discouraging overly complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BIC MODEL SELECTION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Testing K values: {K_range}\")\n",
    "print(f\"Each K fitted with {n_init} random initializations\")\n",
    "print(\"\\nThis may take a few minutes...\\n\")\n",
    "\n",
    "# Create BIC selector\n",
    "selector = BICModelSelector(\n",
    "    K_range=K_range,\n",
    "    categories=categories,\n",
    "    max_iter=max_iter,\n",
    "    tol=tol,\n",
    "    n_init=n_init,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    early_stopping_rounds=2\n",
    ")\n",
    "\n",
    "# Fit models for all K values\n",
    "selector.fit(X, verbose=True, parallel_strategy='auto')\n",
    "\n",
    "# Get results\n",
    "results = selector.get_all_results()\n",
    "selected_K = selector.best_K\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL SELECTION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Selected K: {selected_K}\")\n",
    "print(f\"True K:     {K_true}\")\n",
    "\n",
    "if selected_K == K_true:\n",
    "    print(\"\\n‚úì SUCCESS: Correctly identified the true number of classes!\")\n",
    "else:\n",
    "    print(f\"\\n‚úó MISMATCH: Selected K={selected_K}, but true K={K_true}\")\n",
    "\n",
    "print(\"\\nBIC values for all tested K:\")\n",
    "for k, bic, loglik in zip(results['K_range'], results['bic_values'], results['log_likelihoods']):\n",
    "    marker = \"<-- SELECTED\" if k == selected_K else \"\"\n",
    "    true_marker = \"(TRUE K)\" if k == K_true else \"\"\n",
    "    print(f\"  K={k}: BIC={bic:10.2f}, Log-lik={loglik:10.2f}  {true_marker}{marker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize BIC Curve\n",
    "\n",
    "The BIC curve helps us understand the model selection process. We expect to see:\n",
    "- BIC decreasing as K increases (better fit)\n",
    "- BIC increasing after the optimal K (complexity penalty dominates)\n",
    "- A clear minimum at or near the true K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot BIC curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "plot_bic_curve(\n",
    "    K_values=results['K_range'],\n",
    "    bic_values=results['bic_values'],\n",
    "    log_likelihoods=results['log_likelihoods'],\n",
    "    selected_K=selected_K,\n",
    "    true_K=K_true,\n",
    "    save_path=None,  # Don't save, display inline\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- The blue line shows BIC values (lower is better)\")\n",
    "print(\"- The orange line shows log-likelihood (higher is better)\")\n",
    "print(\"- The red dashed line marks the selected K\")\n",
    "print(\"- The green dashed line marks the true K\")\n",
    "print(\"\\nNotice how log-likelihood always improves with more classes,\")\n",
    "print(\"but BIC penalizes complexity, leading to an optimal K.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze the Selected Model\n",
    "\n",
    "Now we'll analyze the model selected by BIC and compare it to the true model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Mixture Weights (œÄ)\n",
    "\n",
    "The mixture weights $\\pi_k$ represent the probability that a randomly selected observation belongs to class $k$. Let's compare the estimated mixture weights with the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get estimated parameters\n",
    "estimated_params = selector.get_best_model()\n",
    "estimated_pi = estimated_params['pi']\n",
    "estimated_theta = estimated_params['theta']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MIXTURE WEIGHTS COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if selected_K == K_true:\n",
    "    print(f\"\\n{'Class':<8} {'True œÄ':<12} {'Estimated œÄ':<12} {'Absolute Error':<15}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for k in range(K_true):\n",
    "        error = abs(true_pi[k] - estimated_pi[k])\n",
    "        print(f\"{k:<8} {true_pi[k]:<12.4f} {estimated_pi[k]:<12.4f} {error:<15.4f}\")\n",
    "    \n",
    "    # Compute overall error metrics\n",
    "    mae = np.mean(np.abs(true_pi - estimated_pi))\n",
    "    rmse = np.sqrt(np.mean((true_pi - estimated_pi)**2))\n",
    "    \n",
    "    print(f\"\\nOverall Metrics:\")\n",
    "    print(f\"  Mean Absolute Error (MAE):  {mae:.6f}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {rmse:.6f}\")\n",
    "else:\n",
    "    print(f\"\\nCannot compare parameters: K mismatch (selected={selected_K}, true={K_true})\")\n",
    "    print(f\"\\nEstimated mixture weights (K={selected_K}):\")\n",
    "    for k in range(selected_K):\n",
    "        print(f\"  Class {k}: œÄ_{k} = {estimated_pi[k]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize mixture weights comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "if selected_K == K_true:\n",
    "    plot_mixture_weights(\n",
    "        pi=estimated_pi,\n",
    "        true_pi=true_pi,\n",
    "        save_path=None,\n",
    "        ax=ax\n",
    "    )\n",
    "else:\n",
    "    plot_mixture_weights(\n",
    "        pi=estimated_pi,\n",
    "        true_pi=None,\n",
    "        save_path=None,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if selected_K == K_true:\n",
    "    print(\"\\nThe plot shows estimated (blue) vs true (orange) mixture weights.\")\n",
    "    print(\"Good parameter recovery is indicated by similar bar heights.\")\n",
    "else:\n",
    "    print(\"\\nThe plot shows estimated mixture weights for the selected model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Categorical Probabilities (Œ∏)\n",
    "\n",
    "The categorical probabilities $\\theta_{rkc} = P(X^{(r)} = c | H = k)$ define how each latent class generates observed categories for each variable. Let's visualize these for the first several variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_K == K_true:\n",
    "    # Compute theta errors\n",
    "    theta_mae = np.mean(np.abs(true_theta - estimated_theta))\n",
    "    theta_rmse = np.sqrt(np.mean((true_theta - estimated_theta)**2))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CATEGORICAL PROBABILITIES (Œ∏) - ERROR METRICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Mean Absolute Error (MAE):  {theta_mae:.6f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {theta_rmse:.6f}\")\n",
    "    \n",
    "    # Per-class errors\n",
    "    print(f\"\\nPer-Class MAE:\")\n",
    "    for k in range(K_true):\n",
    "        class_mae = np.mean(np.abs(true_theta[k] - estimated_theta[k]))\n",
    "        print(f\"  Class {k}: {class_mae:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical probabilities\n",
    "print(\"\\nVisualizing categorical probabilities for the first 10 variables...\\n\")\n",
    "\n",
    "if selected_K == K_true:\n",
    "    # Show comparison with true values\n",
    "    fig = plot_categorical_probabilities(\n",
    "        theta=estimated_theta,\n",
    "        categories=categories,\n",
    "        true_theta=true_theta,\n",
    "        max_vars=10,\n",
    "        save_path=None\n",
    "    )\n",
    "    print(\"\\nBlue bars show estimated probabilities, orange bars show true probabilities.\")\n",
    "    print(\"Each subplot represents one variable, showing the probability distribution\")\n",
    "    print(\"of categories for each latent class.\")\n",
    "else:\n",
    "    # Show only estimated values\n",
    "    fig = plot_categorical_probabilities(\n",
    "        theta=estimated_theta,\n",
    "        categories=categories,\n",
    "        true_theta=None,\n",
    "        max_vars=10,\n",
    "        save_path=None\n",
    "    )\n",
    "    print(\"\\nEach subplot shows the estimated probability distribution of categories\")\n",
    "    print(\"for each latent class for one variable.\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Class Assignment Analysis\n",
    "\n",
    "Now let's evaluate how well the model can classify observations into their true latent classes. We'll use the trained model to predict class assignments and compare them with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance with the selected K and fit it\n",
    "# (We need this to get predictions)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASS ASSIGNMENT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nFitting model with selected K={selected_K} to get class predictions...\\n\")\n",
    "\n",
    "final_model = LatentClassModel(K=selected_K, categories=categories, random_state=42)\n",
    "final_model.fit(X, max_iter=max_iter, tol=tol, n_init=n_init, n_jobs=-1, verbose=False)\n",
    "\n",
    "# Get predictions\n",
    "predicted_classes = final_model.predict(X)\n",
    "posterior_probs = final_model.predict_proba(X)\n",
    "\n",
    "print(f\"Model converged: {final_model.converged}\")\n",
    "print(f\"Number of iterations: {final_model.n_iterations}\")\n",
    "print(f\"Final log-likelihood: {final_model.best_log_likelihood:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_K == K_true:\n",
    "    # Visualize confusion matrix\n",
    "    fig = plot_class_assignments(\n",
    "        true_labels=H,\n",
    "        predicted_labels=predicted_classes,\n",
    "        K=K_true,\n",
    "        save_path=None\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute classification accuracy\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(H, predicted_classes)\n",
    "    \n",
    "    # Find optimal label matching (Hungarian algorithm)\n",
    "    # Maximize the trace by minimizing the negative\n",
    "    row_ind, col_ind = linear_sum_assignment(-cm)\n",
    "    \n",
    "    # Remap predicted labels\n",
    "    label_mapping = dict(zip(col_ind, row_ind))\n",
    "    remapped_predictions = np.array([label_mapping[p] for p in predicted_classes])\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(H, remapped_predictions)\n",
    "    \n",
    "    print(f\"\\nClassification Accuracy (after optimal label matching): {accuracy:.4f}\")\n",
    "    print(f\"\\nThis means {accuracy*100:.2f}% of observations were correctly classified\")\n",
    "    print(\"into their true latent class.\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    print(f\"\\nPer-Class Precision:\")\n",
    "    cm_remapped = confusion_matrix(H, remapped_predictions)\n",
    "    for k in range(K_true):\n",
    "        precision = cm_remapped[k, k] / cm_remapped[:, k].sum() if cm_remapped[:, k].sum() > 0 else 0\n",
    "        print(f\"  Class {k}: {precision:.4f}\")\n",
    "    \n",
    "    print(f\"\\nPer-Class Recall:\")\n",
    "    for k in range(K_true):\n",
    "        recall = cm_remapped[k, k] / cm_remapped[k, :].sum() if cm_remapped[k, :].sum() > 0 else 0\n",
    "        print(f\"  Class {k}: {recall:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nCannot compute classification accuracy: K mismatch (selected={selected_K}, true={K_true})\")\n",
    "    print(f\"\\nDistribution of predicted classes:\")\n",
    "    for k in range(selected_K):\n",
    "        count = np.sum(predicted_classes == k)\n",
    "        proportion = count / n\n",
    "        print(f\"  Class {k}: {count} samples ({proportion:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Posterior Probability Analysis\n",
    "\n",
    "The posterior probabilities $P(H=k | X_i)$ tell us how confident the model is about each observation's class assignment. Let's analyze the uncertainty in class assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize posterior probabilities\n",
    "fig = plot_posterior_uncertainty(\n",
    "    posterior_probs=posterior_probs,\n",
    "    predicted_labels=predicted_classes,\n",
    "    K=selected_K,\n",
    "    save_path=None\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Compute statistics on posterior probabilities\n",
    "max_probs = np.max(posterior_probs, axis=1)\n",
    "entropy = -np.sum(posterior_probs * np.log(posterior_probs + 1e-10), axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POSTERIOR PROBABILITY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nMaximum posterior probability:\")\n",
    "print(f\"  Mean:   {np.mean(max_probs):.4f}\")\n",
    "print(f\"  Median: {np.median(max_probs):.4f}\")\n",
    "print(f\"  Min:    {np.min(max_probs):.4f}\")\n",
    "print(f\"  Max:    {np.max(max_probs):.4f}\")\n",
    "\n",
    "print(f\"\\nPosterior entropy (uncertainty):\")\n",
    "print(f\"  Mean:   {np.mean(entropy):.4f}\")\n",
    "print(f\"  Median: {np.median(entropy):.4f}\")\n",
    "\n",
    "# Count high-confidence predictions\n",
    "high_confidence = np.sum(max_probs > 0.9) / n\n",
    "low_confidence = np.sum(max_probs < 0.5) / n\n",
    "\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "print(f\"  High confidence (max prob > 0.9): {high_confidence:.1%}\")\n",
    "print(f\"  Low confidence (max prob < 0.5):  {low_confidence:.1%}\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"- Higher maximum probabilities indicate more confident classifications\")\n",
    "print(f\"- Lower entropy indicates less uncertainty in class assignments\")\n",
    "print(f\"- {high_confidence*100:.1f}% of observations have very clear class membership\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Summary and Conclusions\n",
    "\n",
    "Let's summarize the key findings from this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Data Configuration:\")\n",
    "print(f\"   - Sample size: {n}\")\n",
    "print(f\"   - True number of classes: {K_true}\")\n",
    "print(f\"   - Number of variables: {m}\")\n",
    "print(f\"   - Categories per variable: {C}\")\n",
    "\n",
    "print(f\"\\nüîç Model Selection:\")\n",
    "print(f\"   - K values tested: {K_range}\")\n",
    "print(f\"   - Selected K: {selected_K}\")\n",
    "print(f\"   - Selection correct: {'‚úì YES' if selected_K == K_true else '‚úó NO'}\")\n",
    "\n",
    "if selected_K == K_true:\n",
    "    print(f\"\\nüìà Parameter Recovery:\")\n",
    "    print(f\"   - Mixture weights MAE: {mae:.6f}\")\n",
    "    print(f\"   - Mixture weights RMSE: {rmse:.6f}\")\n",
    "    print(f\"   - Categorical probabilities MAE: {theta_mae:.6f}\")\n",
    "    print(f\"   - Categorical probabilities RMSE: {theta_rmse:.6f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Classification Performance:\")\n",
    "    print(f\"   - Overall accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"   - High confidence predictions: {high_confidence:.1%}\")\n",
    "    print(f\"   - Mean maximum posterior prob: {np.mean(max_probs):.4f}\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Algorithm Performance:\")\n",
    "print(f\"   - Converged: {final_model.converged}\")\n",
    "print(f\"   - Iterations: {final_model.n_iterations}\")\n",
    "print(f\"   - Final log-likelihood: {final_model.best_log_likelihood:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY TAKEAWAYS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if selected_K == K_true:\n",
    "    print(\"\\n‚úì The BIC criterion successfully identified the correct number of classes.\")\n",
    "    print(\"\\n‚úì Parameter estimates closely match the true values, demonstrating\")\n",
    "    print(\"  effective parameter recovery with the EM algorithm.\")\n",
    "    print(f\"\\n‚úì The model achieves {accuracy*100:.1f}% classification accuracy, indicating\")\n",
    "    print(\"  strong ability to recover latent class structure from observed data.\")\n",
    "    print(f\"\\n‚úì {high_confidence*100:.1f}% of observations have highly confident class assignments\")\n",
    "    print(\"  (posterior probability > 0.9), suggesting clear separation between classes.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  The BIC criterion selected K={selected_K} instead of true K={K_true}.\")\n",
    "    print(\"\\n   This could be due to:\")\n",
    "    print(\"   - Limited sample size relative to model complexity\")\n",
    "    print(\"   - Weak separation between some latent classes\")\n",
    "    print(\"   - Random variation in this particular dataset\")\n",
    "    print(\"\\n   Consider:\")\n",
    "    print(\"   - Increasing sample size (n)\")\n",
    "    print(\"   - Running multiple replications to assess stability\")\n",
    "    print(\"   - Examining the BIC curve for near-optimal solutions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF DEMO\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook demonstrated a complete latent class modeling workflow. To explore further:\n",
    "\n",
    "1. **Experiment with different configurations**: Try varying `n`, `K_true`, `m`, or `C` in the configuration cell and re-run the notebook to see how results change.\n",
    "\n",
    "2. **Explore robustness**: Run this analysis multiple times with different random seeds to assess the stability of BIC selection and parameter recovery.\n",
    "\n",
    "3. **Test with real data**: Use `main.py` to analyze your own categorical datasets:\n",
    "   ```bash\n",
    "   python main.py --data your_data.csv --output-prefix analysis\n",
    "   ```\n",
    "\n",
    "4. **Run simulation studies**: Execute comprehensive simulation studies to evaluate performance across different scenarios:\n",
    "   ```bash\n",
    "   make simulate\n",
    "   ```\n",
    "\n",
    "5. **Examine the source code**: All functions used in this notebook are in the `src/` folder. Review the implementation to understand the algorithms in detail.\n",
    "\n",
    "For more information, see the project README."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
